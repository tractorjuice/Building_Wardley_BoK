{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tractorjuice/Building_BoK/blob/main/Building_Wardley_Mapping_Body_of_Knowledge_Part_14_Upsert_Podcast_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07c1e3b9"
      },
      "source": [
        "# Wardley Mapping Body of Knowledge Using Langchain & OpenAI\n",
        "## Part 14, create the vector database\n",
        "\n",
        "This example shows how to create and query an internal knowledge base using ChatGPT.\n",
        "\n",
        "This does requires a GPU runtime."
      ],
      "id": "07c1e3b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZMGuOEMrG2V"
      },
      "source": [
        "### Runtime Checks"
      ],
      "id": "pZMGuOEMrG2V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b95p5xdwLUSC"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  gpu_info = !nvidia-smi\n",
        "except:\n",
        "  print('No GPU')\n",
        "else:\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "  print(gpu_info)"
      ],
      "id": "b95p5xdwLUSC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcOHVNQGuzRT"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "id": "BcOHVNQGuzRT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UqlAAxTXnGF"
      },
      "source": [
        "## Set Up\n"
      ],
      "id": "0UqlAAxTXnGF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3l-ZazUZPR2"
      },
      "source": [
        "Mount Google Drive"
      ],
      "id": "K3l-ZazUZPR2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trki7a-jZNzf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "trki7a-jZNzf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq7f-05_QjAH"
      },
      "source": [
        "Check / create directory structure"
      ],
      "id": "oq7f-05_QjAH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmebnpL_KA5N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "KB_FOLDER = \"/content/gdrive/Mydrive/WardleyKB\"  # Google drive folder to save the knowledgebase\n",
        "MAPS = os.path.join(KB_FOLDER, \"maps/research2022\")  # Sub-directory for research 2022 files\n",
        "MAPS_DATASTORE = os.path.join(KB_FOLDER, \"maps/datastore\")  # Sub-directory for maps FAIS datastore files\n",
        "YT = os.path.join(KB_FOLDER, \"youtube\")  # Sub-directory for YouTube FAIS datastore files\n",
        "YT_DATASTORE = os.path.join(YT, \"datastore\")  # Sub-directory for YouTube FAIS datastore files\n",
        "YT_AUDIO = os.path.join(YT, \"audio\")  # Sub-directory for audio files\n",
        "YT_TRANSCRIPTS = os.path.join(YT_AUDIO, \"transcripts\")  # Sub-directory for transcripts of audio files\n",
        "YT_TRANSCRIPTS_TEXT = os.path.join(YT_TRANSCRIPTS, \"full_text\")  # Sub-directory for text of audio files\n",
        "YT_TRANSCRIPTS_WHISPER = os.path.join(YT_TRANSCRIPTS, \"whisper_chunks\")  # Sub-directory for Whisper chunks of audio files\n",
        "YT_TRANSCRIPTS_DATASTORE = os.path.join(YT_TRANSCRIPTS, \"datastore\")  # Sub-directory for books FAIS datastore file\n",
        "PODCAST = os.path.join(KB_FOLDER, \"podcast\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_DATASTORE = os.path.join(PODCAST, \"datastore\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_AUDIO = os.path.join(PODCAST, \"audio\")  # Sub-directory for YouTube FAIS datastore files\n",
        "PODCAST_TRANSCRIPTS = os.path.join(PODCAST, \"transcripts\")  # Sub-directory for YouTube FAIS datastore files\n",
        "BOOKS = os.path.join(KB_FOLDER, \"books\")  # Sub-directory for books FAIS datastore file\n",
        "BOOKS_DATASTORE = os.path.join(BOOKS, \"datastore\")  # Sub-directory for books FAIS datastore file\n",
        "BOOK = os.path.join(BOOKS, \"book\")  # Sub-directory for files of the pages from Wardley book\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(KB_FOLDER):\n",
        "    os.makedirs(KB_FOLDER)\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(MAPS):\n",
        "    os.makedirs(MAPS)\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(MAPS_DATASTORE):\n",
        "    os.makedirs(MAPS_DATASTORE)\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(YT_DATASTORE):\n",
        "    os.makedirs(YT_DATASTORE)\n",
        "\n",
        "# Check if directory exists and if not, create it\n",
        "if not os.path.exists(BOOKS_DATASTORE):\n",
        "    os.makedirs(BOOKS_DATASTORE)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_AUDIO):\n",
        "    os.makedirs(YT_AUDIO)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS):\n",
        "    os.makedirs(YT_TRANSCRIPTS)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS_TEXT):\n",
        "    os.makedirs(YT_TRANSCRIPTS_TEXT)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(YT_TRANSCRIPTS_WHISPER):\n",
        "    os.makedirs(YT_TRANSCRIPTS_WHISPER)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(BOOKS):\n",
        "    os.makedirs(BOOKS)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(BOOK):\n",
        "    os.makedirs(BOOK)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST):\n",
        "    os.makedirs(PODCAST)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST_DATASTORE):\n",
        "    os.makedirs(PODCAST_DATASTORE)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST_AUDIO):\n",
        "    os.makedirs(PODCAST_AUDIO)\n",
        "\n",
        "# Check if sub-directory exists and if not, create it\n",
        "if not os.path.exists(PODCAST_TRANSCRIPTS):\n",
        "    os.makedirs(PODCAST_TRANSCRIPTS)"
      ],
      "id": "jmebnpL_KA5N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03__ie72B8J_"
      },
      "source": [
        "Install required dependencies"
      ],
      "id": "03__ie72B8J_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6TkUqCJB_2X"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q openai\n",
        "!pip install -q tiktoken"
      ],
      "id": "W6TkUqCJB_2X"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUbD-eXCXNy-"
      },
      "source": [
        "Set up OPEN_API_KEY and necessary variables"
      ],
      "id": "TUbD-eXCXNy-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY7CJZoh5cma"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" #Add your OpenAI API key here\n",
        "\n",
        "#MODEL = \"gpt-3\"\n",
        "#MODEL = \"gpt-3.5-turbo\"\n",
        "#MODEL = \"gpt-3.5-turbo-0613\"\n",
        "#MODEL = \"gpt-3.5-turbo-16k\"\n",
        "MODEL = \"gpt-3.5-turbo-16k-0613\"\n",
        "#MODEL = \"gpt-4\"\n",
        "#MODEL = \"gpt-4-0613\"\n",
        "#MODEL = \"gpt-4-32k-0613\""
      ],
      "id": "tY7CJZoh5cma"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1TNYcmcqnPD"
      },
      "source": [
        "Initialise preferred vectorstore"
      ],
      "id": "o1TNYcmcqnPD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHlPznGkxKD9"
      },
      "outputs": [],
      "source": [
        "vectorstore = 'FAIS' # Set to 'Pinecone' or 'FAISS' for the vector datbase. If using FAISS, no GPU required"
      ],
      "id": "DHlPznGkxKD9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJdSMzPmuTWS"
      },
      "outputs": [],
      "source": [
        "if vectorstore == 'Pinecone':\n",
        "    !pip install -q pinecone-client\n",
        "    from langchain.vectorstores import Pinecone\n",
        "    from tqdm.auto import tqdm\n",
        "    import pinecone\n",
        "\n",
        "    # initialize pinecone\n",
        "    pinecone.init(\n",
        "        api_key=\"a7c950e0-95b0-49db-a614-b8cb97a9af2a\",  # find at app.pinecone.io\n",
        "        environment=\"us-west4-gcp-free\"  # next to api key in console\n",
        "        )\n",
        "\n",
        "    index_name = \"knowledge\" # Put your Pincecone index name here\n",
        "    name_space = \"wardleykb\" # Put your Pincecone namespace here\n",
        "\n",
        "else:\n",
        "    !pip install -q faiss-cpu\n",
        "    from langchain.vectorstores import FAISS\n"
      ],
      "id": "eJdSMzPmuTWS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mHZRgDKXv1r"
      },
      "source": [
        "# Build the datastore"
      ],
      "id": "1mHZRgDKXv1r"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph7oFppn_V5N"
      },
      "source": [
        "## Split text and create chunks, create metadata and upsert embeddings to vectorstore"
      ],
      "id": "Ph7oFppn_V5N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D1uKLEKLsz6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import tiktoken"
      ],
      "id": "-D1uKLEKLsz6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K06kr6G8jSds"
      },
      "outputs": [],
      "source": [
        "#Required for YouTube title and author extraction\n",
        "!pip install -q pytube\n",
        "import pytube"
      ],
      "id": "K06kr6G8jSds"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOdewvujOuaP"
      },
      "source": [
        "### Upsert embeddings to preferred vector store"
      ],
      "id": "VOdewvujOuaP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHviRb3WmbYW"
      },
      "outputs": [],
      "source": [
        "docs = []\n",
        "metadatas = []\n",
        "unique_podcast_ids = []\n",
        "transcriptions = []\n",
        "counter = 0\n",
        "texts = []\n",
        "start_times = []\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50, separator=\"\\n\")\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "with open(f'{PODCAST}/podcasts.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        # Remove linebreak which is the last character of the string\n",
        "        curr_place = line[:-1]\n",
        "        # Add item to the list\n",
        "        unique_podcast_ids.append(curr_place)\n",
        "\n",
        "total_podcasts = len(unique_podcast_ids)\n",
        "\n",
        "for podcast_id in unique_podcast_ids:\n",
        "    counter = counter + 1\n",
        "\n",
        "    # Remove file extension from podcast\n",
        "    podcast_name = os.path.splitext(podcast_id)[0]\n",
        "\n",
        "    transcript_filename = f'{PODCAST_TRANSCRIPTS}/' + podcast_name + '_large.txt'\n",
        "    url = \"https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5jYXB0aXZhdGUuZm0vZGF0YS1tZXNoLXJhZGlv/episode/\" + podcast_id\n",
        "    try:\n",
        "        file = open(transcript_filename, 'r')\n",
        "    except:\n",
        "        print(f'{counter} of {total_podcasts}: File does not exist {transcript_filename}, skipping.')\n",
        "    else:\n",
        "        print(f'{counter} of {total_podcasts}: Loading {transcript_filename} ......\\n')\n",
        "        transcription = json.load(file)\n",
        "        texts = []\n",
        "        start_times = []\n",
        "        docs = []\n",
        "        metadatas = []\n",
        "\n",
        "        for chunk in transcription['chunks']:\n",
        "            if chunk['timestamp'][0] is not None:\n",
        "                text = chunk['text']\n",
        "                start = int(chunk['timestamp'][0])\n",
        "                texts.append(text)\n",
        "                start_times.append(start)\n",
        "\n",
        "        for i, d in enumerate(texts):\n",
        "            splits = text_splitter.split_text(d)\n",
        "            docs.extend(splits)\n",
        "            metadatas.extend([{\"source\": 'Podcast', \"start_time\": start_times[i], \"source_id\": podcast_id}])\n",
        "\n",
        "        if vectorstore == 'Pinecone':\n",
        "            try:\n",
        "                vector_store = Pinecone.from_texts(docs, embeddings, metadatas=metadatas, index_name=index_name, namespace=name_space)\n",
        "            except:\n",
        "                print(\"Error upserting data into the vectorstore\\n\")\n",
        "        else:\n",
        "            try:\n",
        "                vector_store = FAISS.from_texts(docs, embeddings, metadatas=metadatas)\n",
        "                if os.path.exists(f\"{PODCAST_DATASTORE}/index.faiss\"):\n",
        "                    existing_index=FAISS.load_local(f\"{PODCAST_DATASTORE}\", embeddings)\n",
        "                    existing_index.merge_from(vector_store)\n",
        "                    existing_index.save_local(f\"{PODCAST_DATASTORE}\")\n",
        "                else:\n",
        "                    vector_store.save_local(f\"{PODCAST_DATASTORE}\") # Download the files `$DATA_STORE_DIR/index.faiss` and `$DATA_STORE_DIR/index.pkl` to local\n",
        "            except:\n",
        "                print(\"Error upserting data into the vectorstore\\n\")"
      ],
      "id": "UHviRb3WmbYW"
    },
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pZMGuOEMrG2V",
        "0UqlAAxTXnGF",
        "DMUH-ZWkgoZS"
      ],
      "provenance": [],
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "b1677b440931f40d89ef8be7bf03acb108ce003de0ac9b18e8d43753ea2e7103"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
